{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NCBI](NCBI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for coding sequences in genomes using BLAST and Python\n",
    "\n",
    "This notebook takes a sequence of a budding yeast gene and identifies the orthologs in genome sequences. In the process, it'll collect both the coding sequences and the encoded protein sequences for the orthologs.\n",
    "\n",
    "This notebook builds on the previous ones. See those for more information and acknowledgements.  It also collects subsequences from a collection of PacBio sequenced yeast genomes from [Yue et al 2017](https://www.ncbi.nlm.nih.gov/pubmed/28416820). This tutorial is further expanded to included using PatMatch on the mined ortholog protein sequences [here](GSD/GSD%20Rpb1_orthologs_in_PB_genomes.ipynb#GSD:-Rpb1-orthologs-in-PB-genomes) and [here](GSD/GSD%20Rpb1_orthologs_in_1011_genomes.ipynb).\n",
    "\n",
    "\n",
    "Reference for sequence data:  \n",
    "[Contrasting evolutionary genome dynamics between domesticated and wild yeasts.\n",
    "Yue JX, Li J, Aigrain L, Hallin J, Persson K, Oliver K, BergstrÃ¶m A, Coupland P, Warringer J, Lagomarsino MC, Fischer G, Durbin R, Liti G. Nat Genet. 2017 Jun;49(6):913-924. doi: 10.1038/ng.3847. Epub 2017 Apr 17. PMID: 28416820](https://www.ncbi.nlm.nih.gov/pubmed/28416820)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "![overview of steps](../images/ortholog_mining_summarized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "The next cell allows you to examine a gene of interest. (If there were a lot of genes to examine, we could use [papermill](https://github.com/nteract/papermill) to provide the necessary information.)\n",
    "\n",
    "If you don't want to get the gene sequence from elsewhere on the internet, set `get_seq_from_link` to `False` and ignore the value for `link_to_FASTA_of_gene`. You'll be prompted later to edit a file in the session.\n",
    "\n",
    "(Caveat: this is written for genes with no introns; their presence would only become important when trying to translate in late stages of this workflow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name = \"VPH1\" # can be what you want to use in this notebook; not used to match anything external\n",
    "size_expected = 2523 #use bp length of coding sequence at SGD\n",
    "get_seq_from_link = True #Change what is between quotes on next line if `True`\n",
    "link_to_FASTA_of_gene = \"https://gist.githubusercontent.com/fomightez/f46b0624f1d8e3abb6ff908fc447e63b/raw/625eaba76bb54e16032f90c8812350441b753a0c/uz_S288C_YOR270C_VPH1_coding.fsa\"\n",
    "#**Possible future enhancement would be to add getting the FASTA of the gene from Yeastmine with just systematic id using get_gene_genomic_seq_as_FASTA.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the genome data, the `blast_to_df` script, and target sequence by running these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13759  100 13759    0     0  32604      0 --:--:-- --:--:-- --:--:-- 32527\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   1745      0 --:--:-- --:--:-- --:--:--  1745\n",
      "100 3687k  100 3687k    0     0  7346k      0 --:--:-- --:--:-- --:--:-- 21.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   1648      0 --:--:-- --:--:-- --:--:--  1648\n",
      "100 3387k  100 3387k    0     0  8797k      0 --:--:-- --:--:-- --:--:-- 18.3M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0    579      0 --:--:-- --:--:-- --:--:--   577\n",
      "100 3348k  100 3348k    0     0  4975k      0 --:--:-- --:--:-- --:--:-- 4975k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2342      0 --:--:-- --:--:-- --:--:--  2342\n",
      "100 3406k  100 3406k    0     0  7638k      0 --:--:-- --:--:-- --:--:-- 12.9M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2617      0 --:--:-- --:--:-- --:--:--  2617\n",
      "100 3357k  100 3357k    0     0  11.5M      0 --:--:-- --:--:-- --:--:-- 11.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2542      0 --:--:-- --:--:-- --:--:--  2542\n",
      "100 3375k  100 3375k    0     0  9221k      0 --:--:-- --:--:-- --:--:-- 9221k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2373      0 --:--:-- --:--:-- --:--:--  2373\n",
      "100 3332k  100 3332k    0     0  8332k      0 --:--:-- --:--:-- --:--:-- 8332k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3122      0 --:--:-- --:--:-- --:--:--  3068\n",
      "100 3658k  100 3658k    0     0  9032k      0 --:--:-- --:--:-- --:--:-- 9032k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   1745      0 --:--:-- --:--:-- --:--:--  1728\n",
      "100 3350k  100 3350k    0     0  7939k      0 --:--:-- --:--:-- --:--:-- 7939k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2311      0 --:--:-- --:--:-- --:--:--  2282\n",
      "100 3349k  100 3349k    0     0  9202k      0 --:--:-- --:--:-- --:--:-- 9202k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   1780      0 --:--:-- --:--:-- --:--:--  1780\n",
      "100 3701k  100 3701k    0     0  8985k      0 --:--:-- --:--:-- --:--:-- 14.4M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2438      0 --:--:-- --:--:-- --:--:--  2507\n",
      "100 3362k  100 3362k    0     0  8241k      0 --:--:-- --:--:-- --:--:-- 12.5M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"blast_to_df.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/blast-utilities/blast_to_df.py\n",
    "import pandas as pd\n",
    "# Prepare for getting PacBio (Yue et al 2017 sequences)\n",
    "#make a list of the strain designations\n",
    "yue_et_al_strains = [\"S288C\",\"DBVPG6044\",\"DBVPG6765\",\"SK1\",\"Y12\",\n",
    "                     \"YPS128\",\"UWOPS034614\",\"CBS432\",\"N44\",\"YPS138\",\n",
    "                     \"UFRJ50816\",\"UWOPS919171\"]\n",
    "# Get & unpack the genome sequences from strains \n",
    "for s in yue_et_al_strains:\n",
    "    !curl -LO http://yjx1217.github.io/Yeast_PacBio_2016/data/Nuclear_Genome/{s}.genome.fa.gz\n",
    "    !gunzip -f {s}.genome.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "S288C.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6044.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6765.genome.fa chromosome identifiers tagged.\n",
      "SK1.genome.fa chromosome identifiers tagged.\n",
      "Y12.genome.fa chromosome identifiers tagged.\n",
      "YPS128.genome.fa chromosome identifiers tagged.\n",
      "UWOPS034614.genome.fa chromosome identifiers tagged.\n",
      "CBS432.genome.fa chromosome identifiers tagged.\n",
      "N44.genome.fa chromosome identifiers tagged.\n",
      "YPS138.genome.fa chromosome identifiers tagged.\n",
      "UFRJ50816.genome.fa chromosome identifiers tagged.\n",
      "UWOPS919171.genome.fa chromosome identifiers tagged."
     ]
    }
   ],
   "source": [
    "# add identifiers to each `chr` so results for each strain clear later\n",
    "chromosome_id_prefix = \"chr\"\n",
    "def add_strain_id_to_description_line(file,strain_id):\n",
    "    '''\n",
    "    Takes a file and edits every description line to add \n",
    "    strain_id after the caret.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    rest_o_line = line.split(\">\")\n",
    "                    new_line = \">\"+strain_id + rest_o_line[1]\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\n{} chromosome identifiers tagged.\".format(file))\n",
    "\n",
    "for s in yue_et_al_strains:\n",
    "    add_strain_id_to_description_line(s+\".genome.fa\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2596  100  2596    0     0  11746      0 --:--:-- --:--:-- --:--:-- 11746\n"
     ]
    }
   ],
   "source": [
    "# Get SGD gene sequence in FASTA format to search for best matches in the genomes\n",
    "import sys\n",
    "gene_filen = gene_name + \".fsa\"\n",
    "if get_seq_from_link:\n",
    "    !curl -o {gene_filen} {link_to_FASTA_of_gene}\n",
    "else:\n",
    "    !touch {gene_filen}\n",
    "    sys.stderr.write(\"\\nEDIT THE FILE '{}' TO CONTAIN \"\n",
    "        \"YOUR GENE OF INTEREST (FASTA-FORMATTED)\"\n",
    "        \".\".format(gene_filen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are prepared to run BLAST to search each PacBio-sequenced genomes for the best match to a gene from the Saccharomyces cerevisiae strain S288C reference sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BLAST to search for matches to gene in reference genome at SGD\n",
    "\n",
    "We are going to search the [Saccharomyces cerevisiae Genome Database](http:yeastgenome.org) (SGD) with a reference genome from S288C. This will go through each genome, make a database, and search for matches. The information on the best match will be collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blast_to_df import blast_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y12.genome.fa',\n",
       " 'UWOPS034614.genome.fa',\n",
       " 'N44.genome.fa',\n",
       " 'UFRJ50816.genome.fa',\n",
       " 'DBVPG6044.genome.fa',\n",
       " 'S288C.genome.fa',\n",
       " 'YPS128.genome.fa',\n",
       " 'UWOPS919171.genome.fa',\n",
       " 'CBS432.genome.fa',\n",
       " 'YPS138.genome.fa',\n",
       " 'SK1.genome.fa',\n",
       " 'DBVPG6765.genome.fa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of all `genome.fa` files, excluding `genome.fa.nhr` and `genome.fa.nin` and `genome.fansq`\n",
    "# The excluding was only necessary because I had run some queries preiminarily in development. Normally, it would just be the `.re.fa` at the outset.\n",
    "fn_to_check = \"genome.fa\" \n",
    "genomes = []\n",
    "import os\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, '*'+fn_to_check):\n",
    "        if not file.endswith(\".nhr\") and not file.endswith(\".nin\") and not file.endswith(\".nsq\") :\n",
    "            genomes.append(file)\n",
    "genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:37\n",
      "New DB name:   /home/jovyan/notebooks/Y12.genome.fa\n",
      "New DB title:  Y12.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.353903 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:38\n",
      "New DB name:   /home/jovyan/notebooks/UWOPS034614.genome.fa\n",
      "New DB title:  UWOPS034614.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.280217 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:40\n",
      "New DB name:   /home/jovyan/notebooks/N44.genome.fa\n",
      "New DB title:  N44.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.338185 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:41\n",
      "New DB name:   /home/jovyan/notebooks/UFRJ50816.genome.fa\n",
      "New DB title:  UFRJ50816.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.315063 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:42\n",
      "New DB name:   /home/jovyan/notebooks/DBVPG6044.genome.fa\n",
      "New DB title:  DBVPG6044.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.318943 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:44\n",
      "New DB name:   /home/jovyan/notebooks/S288C.genome.fa\n",
      "New DB title:  S288C.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.315348 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:45\n",
      "New DB name:   /home/jovyan/notebooks/YPS128.genome.fa\n",
      "New DB title:  YPS128.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.344856 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:47\n",
      "New DB name:   /home/jovyan/notebooks/UWOPS919171.genome.fa\n",
      "New DB title:  UWOPS919171.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.280303 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:48\n",
      "New DB name:   /home/jovyan/notebooks/CBS432.genome.fa\n",
      "New DB title:  CBS432.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.264529 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:49\n",
      "New DB name:   /home/jovyan/notebooks/YPS138.genome.fa\n",
      "New DB title:  YPS138.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.30673 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:51\n",
      "New DB name:   /home/jovyan/notebooks/SK1.genome.fa\n",
      "New DB title:  SK1.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.310356 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/14/2019 20:44:52\n",
      "New DB name:   /home/jovyan/notebooks/DBVPG6765.genome.fa\n",
      "New DB title:  DBVPG6765.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.36078 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    }
   ],
   "source": [
    "SGD_gene = gene_filen\n",
    "dfs = []\n",
    "for genome in genomes:\n",
    "    !makeblastdb -in {genome} -dbtype nucl\n",
    "    result = !blastn -query {SGD_gene} -db {genome} -outfmt \"6 qseqid sseqid stitle pident qcovs length mismatch gapopen qstart qend sstart send qframe sframe frames evalue bitscore qseq sseq\" -task blastn\n",
    "    from blast_to_df import blast_to_df\n",
    "    blast_df = blast_to_df(result.n)\n",
    "    dfs.append(blast_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes in the list `dfs` into one dataframe\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the df\n",
    "filen_prefix = gene_name + \"_orthologBLASTdf\"\n",
    "df.to_pickle(filen_prefix+\".pkl\")\n",
    "df.to_csv(filen_prefix+'.tsv', sep='\\t',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>stitle</th>\n",
       "      <th>pident</th>\n",
       "      <th>qcovs</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>qframe</th>\n",
       "      <th>sframe</th>\n",
       "      <th>frames</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "      <th>qseq</th>\n",
       "      <th>sseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>Y12chrXV</td>\n",
       "      <td>Y12chrXV</td>\n",
       "      <td>99.762</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>800556</td>\n",
       "      <td>798034</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4524.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>UWOPS034614chrXV</td>\n",
       "      <td>UWOPS034614chrXV</td>\n",
       "      <td>99.723</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>811836</td>\n",
       "      <td>809314</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4518.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>N44chrXV</td>\n",
       "      <td>N44chrXV</td>\n",
       "      <td>93.460</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>804897</td>\n",
       "      <td>802375</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3806.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>UFRJ50816chrXV</td>\n",
       "      <td>UFRJ50816chrXV</td>\n",
       "      <td>93.341</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>917297</td>\n",
       "      <td>914775</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3793.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>DBVPG6044chrXV</td>\n",
       "      <td>DBVPG6044chrXV</td>\n",
       "      <td>99.643</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>799877</td>\n",
       "      <td>797355</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>S288CchrXV</td>\n",
       "      <td>S288CchrXV</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>830611</td>\n",
       "      <td>828089</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4551.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>YPS128chrXV</td>\n",
       "      <td>YPS128chrXV</td>\n",
       "      <td>99.802</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>820053</td>\n",
       "      <td>817531</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4527.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>UWOPS919171chrXV</td>\n",
       "      <td>UWOPS919171chrXV</td>\n",
       "      <td>93.262</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>789693</td>\n",
       "      <td>787171</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>CBS432chrXV</td>\n",
       "      <td>CBS432chrXV</td>\n",
       "      <td>93.658</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>807717</td>\n",
       "      <td>805195</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>YPS138chrXV</td>\n",
       "      <td>YPS138chrXV</td>\n",
       "      <td>93.302</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>795373</td>\n",
       "      <td>792851</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>SK1chrXV</td>\n",
       "      <td>SK1chrXV</td>\n",
       "      <td>99.643</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>801081</td>\n",
       "      <td>798559</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPH1</td>\n",
       "      <td>DBVPG6765chrXV</td>\n",
       "      <td>DBVPG6765chrXV</td>\n",
       "      <td>99.564</td>\n",
       "      <td>100</td>\n",
       "      <td>2523</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2523</td>\n",
       "      <td>808342</td>\n",
       "      <td>805820</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "      <td>ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qseqid            sseqid            stitle   pident  qcovs  length  \\\n",
       "0   VPH1          Y12chrXV          Y12chrXV   99.762    100    2523   \n",
       "0   VPH1  UWOPS034614chrXV  UWOPS034614chrXV   99.723    100    2523   \n",
       "0   VPH1          N44chrXV          N44chrXV   93.460    100    2523   \n",
       "0   VPH1    UFRJ50816chrXV    UFRJ50816chrXV   93.341    100    2523   \n",
       "0   VPH1    DBVPG6044chrXV    DBVPG6044chrXV   99.643    100    2523   \n",
       "0   VPH1        S288CchrXV        S288CchrXV  100.000    100    2523   \n",
       "0   VPH1       YPS128chrXV       YPS128chrXV   99.802    100    2523   \n",
       "0   VPH1  UWOPS919171chrXV  UWOPS919171chrXV   93.262    100    2523   \n",
       "0   VPH1       CBS432chrXV       CBS432chrXV   93.658    100    2523   \n",
       "0   VPH1       YPS138chrXV       YPS138chrXV   93.302    100    2523   \n",
       "0   VPH1          SK1chrXV          SK1chrXV   99.643    100    2523   \n",
       "0   VPH1    DBVPG6765chrXV    DBVPG6765chrXV   99.564    100    2523   \n",
       "\n",
       "   mismatch  gapopen  qstart  qend  sstart    send  qframe  sframe frames  \\\n",
       "0         6        0       1  2523  800556  798034       1      -1   1/-1   \n",
       "0         7        0       1  2523  811836  809314       1      -1   1/-1   \n",
       "0       165        0       1  2523  804897  802375       1      -1   1/-1   \n",
       "0       168        0       1  2523  917297  914775       1      -1   1/-1   \n",
       "0         9        0       1  2523  799877  797355       1      -1   1/-1   \n",
       "0         0        0       1  2523  830611  828089       1      -1   1/-1   \n",
       "0         5        0       1  2523  820053  817531       1      -1   1/-1   \n",
       "0       170        0       1  2523  789693  787171       1      -1   1/-1   \n",
       "0       160        0       1  2523  807717  805195       1      -1   1/-1   \n",
       "0       169        0       1  2523  795373  792851       1      -1   1/-1   \n",
       "0         9        0       1  2523  801081  798559       1      -1   1/-1   \n",
       "0        11        0       1  2523  808342  805820       1      -1   1/-1   \n",
       "\n",
       "   evalue  bitscore                                               qseq  \\\n",
       "0     0.0    4524.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4518.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    3806.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    3793.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4509.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4551.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4527.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    3784.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    3829.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    3788.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4509.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "0     0.0    4500.0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...   \n",
       "\n",
       "                                                sseq  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...  \n",
       "0  ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCCT...  \n",
       "0  ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...  \n",
       "0  ATGTCAGAGAAGGAGGAAGCGATTTTTCGCTCGGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  \n",
       "0  ATGGCAGAGAAGGAGGAAGCGATTTTTCGCTCTGCTGAAATGGCTT...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally check if any genomes are missing from the BLAST results list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 12\n",
      "results: 12\n",
      "missing: 0\n"
     ]
    }
   ],
   "source": [
    "subjids = df.sseqid.tolist()\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "subjids = [x.split(chromosome_id_prefix)[0] for x in subjids]\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "len_genome_fn_end = len(fn_to_check) + 1 # plus one to accound for the period that will be \n",
    "# between `fn_to_check` and strain_id`, such as `SK1.genome.fa`\n",
    "genome_ids = [x[:-len_genome_fn_end] for x in genomes]\n",
    "#print (genome_ids[0:10])\n",
    "\n",
    "a = set(genome_ids)\n",
    "#print (a)\n",
    "print (\"initial:\",len(a))\n",
    "r = set(subjids)\n",
    "print(\"results:\",len(r))\n",
    "print (\"missing:\",len(a-r))\n",
    "#a - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a quick sanity check. How does expected size compare to max size seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected size of gene: 2523\n",
      "Most frequent size of matches: 2523\n",
      "Maximum size of matches: 2523\n"
     ]
    }
   ],
   "source": [
    "size_seen = df.length.max(0)\n",
    "print (\"Expected size of gene:\", size_expected)\n",
    "print (\"Most frequent size of matches:\", df.length.mode()[0])\n",
    "print (\"Maximum size of matches:\", df.length.max(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the identified, raw sequences\n",
    "\n",
    "Get the expected size centered on the best match, plus a little flanking each because they might not exactly cover the entire open reading frame. (Although, the example here all look to be full size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16964  100 16964    0     0  75395      0 --:--:-- --:--:-- --:--:-- 75395\n",
      "Collecting pyfaidx\n",
      "  Downloading https://files.pythonhosted.org/packages/75/a5/7e2569527b3849ea28d79b4f70d7cf46a47d36459bc59e0efa4e10e8c8b2/pyfaidx-0.5.5.2.tar.gz\n",
      "Requirement already satisfied: six in /srv/conda/lib/python3.7/site-packages (from pyfaidx) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=0.7 in /srv/conda/lib/python3.7/site-packages (from pyfaidx) (40.8.0)\n",
      "Building wheels for collected packages: pyfaidx\n",
      "  Building wheel for pyfaidx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/54/a2/b4/e242e58d23b2808e191b214067880faa46cd2341f363886e0b\n",
      "Successfully built pyfaidx\n",
      "Installing collected packages: pyfaidx\n",
      "Successfully installed pyfaidx-0.5.5.2\n"
     ]
    }
   ],
   "source": [
    "# Get the script for extracting based on position (and install dependency pyfaidx)\n",
    "import os\n",
    "file_needed = \"extract_subsequence_from_FASTA.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/Extract_from_FASTA/extract_subsequence_from_FASTA.py\n",
    "!pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Collected RAW sequences gathered and saved as `VPH1_raw_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "size_expected = size_expected # use value from above, or alter at this point.\n",
    "#size_expected = df.length.max(0) #bp length of SGD coding sequence; should be equivalent and that way not hardcoded?\n",
    "extra_add_to_start = 51 #to allow for 'fuzziness' at starting end\n",
    "extra_add_to_end = 51 #to allow for 'fuzziness' at far end\n",
    "genome_fn_end = \"genome.fa\" \n",
    "\n",
    "\n",
    "def midpoint(items):\n",
    "    '''\n",
    "    takes a iterable of items and returns the midpoint (integer) of the first \n",
    "    and second values\n",
    "    '''\n",
    "    return int((int(items[0])+int(items[1]))/2)\n",
    "\n",
    "#midpoint((1,100))\n",
    "\n",
    "def determine_pos_to_get(match_start,match_end):\n",
    "    '''\n",
    "    Take the start and end of the matched region.\n",
    "    \n",
    "    Calculate midpoint between those and then \n",
    "    center expected size on that to determine\n",
    "    preliminary start and preliminary end to get.\n",
    "    Add the extra basepairs to get at each end\n",
    "    to allow for fuzziness/differences of actual\n",
    "    gene ends for orthologs. \n",
    "    Return the final start and end positions to get.\n",
    "    \n",
    "    '''\n",
    "    center_of_match = midpoint((match_start,match_end))\n",
    "    half_size_expected = int(size_expected/2.0)\n",
    "    if size_expected % 2 != 0:\n",
    "        half_size_expected += 1\n",
    "    start_pos = center_of_match - half_size_expected\n",
    "    end_pos = center_of_match + half_size_expected\n",
    "    start_pos -= extra_add_to_start\n",
    "    end_pos += extra_add_to_end \n",
    "    \n",
    "    # Because of getting some flanking sequences to account for 'fuzziness', it \n",
    "    # is possible the start and end can exceed possible. 'End' is not a problem \n",
    "    # because the `extract_subsequence_from_FASTA.py` script will get as much as\n",
    "    # it from the indicated sequence if a larger than possible number is \n",
    "    # provided. However,'start' can become negative and because the region to \n",
    "    # extract is provided as a string the dash can become a problem. Dealing \n",
    "    # with it here by making sequence positive only.\n",
    "    if start_pos < 0:\n",
    "        raw_amount_missing_at_start = abs(start_pos)# for counterbalancing; needs\n",
    "        # to be collected before `start_pos` adjusted\n",
    "        start_pos = 1\n",
    "        end_pos += 2 * raw_amount_missing_at_start\n",
    "        \n",
    "    return start_pos, end_pos\n",
    "\n",
    "\n",
    "# go through the dataframe using information on each to come up with sequence file, \n",
    "# specific indentifier within sequence file, and the start and end to extract\n",
    "# store these valaues as a list in a dictionary with the strain identifier as the key.\n",
    "extracted_info = {}\n",
    "start,end = 0,0\n",
    "for row in df.itertuples():\n",
    "    #print (row.length)\n",
    "    start_to_get, end_to_get = determine_pos_to_get(row.sstart, row.send)\n",
    "    posns_to_get = \"{}-{}\".format(start_to_get, end_to_get)\n",
    "    record_id = row.sseqid\n",
    "    strain_id = row.sseqid.split(chromosome_id_prefix)[0]\n",
    "    seq_fn = strain_id + \".\" + genome_fn_end\n",
    "    extracted_info[strain_id] = [seq_fn, record_id, posns_to_get]\n",
    "# Use the dictionary to get the sequences\n",
    "for id_ in extracted_info:\n",
    "    #%run extract_subsequence_from_FASTA.py {*extracted_info[id_]} #unpacking doesn't seem to work here in `%run`\n",
    "    %run extract_subsequence_from_FASTA.py {extracted_info[id_][0]} {extracted_info[id_][1]} {extracted_info[id_][2]}\n",
    "\n",
    "#package up the retrieved sequences\n",
    "archive_file_name = gene_name+\"_raw_ortholog_seqs.tar.gz\"\n",
    "# make list of extracted files using fnmatch\n",
    "fn_part_to_match = \"seq_extracted\"\n",
    "collected_seq_files_list = []\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, fn_part_to_match+'*'):\n",
    "        #print (file)\n",
    "        collected_seq_files_list.append(file)\n",
    "!tar czf {archive_file_name} {\" \".join(collected_seq_files_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\n\\nCollected RAW sequences gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))\n",
    "# move the collected raw sequences to a folder in preparation for\n",
    "# extracting encoding sequence from original source below\n",
    "!mkdir raw\n",
    "!mv seq_extracted*.fa raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This archive should contain the \"raw\" sequence for each gene, even if the ends are a little different for each. At minimum, the entire gene sequence is there at this point, with extra on each end being preferable.\n",
    "\n",
    "You should inspect them as soon as possible and adjust the extra sequence to add higher or lower depending on whether the ortholog genes vary more or less respectively. They don't need to be perfect yet because next we are going to extract the longest open reading frame, which presumably demarcates the entire gene. Then we can return to  clean up the collected sequences into just the coding sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect protein translations of the genes and then clean up \"raw\" sequences to just be coding\n",
    "\n",
    "We'll assume the longest translatable frame in the collected \"raw\" sequences encodes the protein sequence for the gene orthologs of interest. These steps are based on [section '20.1.13  Identifying open reading frames'](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299) in the present version of the [Biopython Tutorial and Cookbook](http://biopython.org/DIST/docs/tutorial/Tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to get a script needed for dealing with the strand during the translation and gathering of thge encoding sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8851  100  8851    0     0  47586      0 --:--:-- --:--:-- --:--:-- 47331\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"convert_fasta_to_reverse_complement.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/ConvertSeq/convert_fasta_to_reverse_complement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to collect protein translations of the genes, followed by cleaning up the \"raw\" sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.7/site-packages/Bio/Seq.py:2609: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning)\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS138_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS138_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS138_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS138_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS138_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS919171_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS919171_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS919171_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS919171_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS919171_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `N44_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'N44_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'N44_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In N44_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `N44_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `SK1_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'SK1_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'SK1_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In SK1_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `SK1_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `Y12_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'Y12_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'Y12_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In Y12_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `Y12_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UFRJ50816_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UFRJ50816_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UFRJ50816_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UFRJ50816_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UFRJ50816_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `S288C_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'S288C_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'S288C_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In S288C_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `S288C_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6044_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6044_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6044_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6044_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6044_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6765_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6765_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6765_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6765_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6765_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS034614_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS034614_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS034614_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS034614_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS034614_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS128_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS128_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS128_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS128_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS128_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrXV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `CBS432_VPH1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'CBS432_VPH1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'CBS432_VPH1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In CBS432_VPH1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `CBS432_VPH1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********"
     ]
    }
   ],
   "source": [
    "# find the featured open reading frame and collect presumed protein sequences\n",
    "# Collect the corresponding encoding sequence from the original source\n",
    "def len_ORF(items):\n",
    "    # orf is fourth item in the tuples\n",
    "    return len(items[3])\n",
    "def find_orfs_with_trans(seq, trans_table, min_protein_length):\n",
    "    '''\n",
    "    adapted from the present section '20.1.13  Identifying open reading frames'\n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299 in the \n",
    "    present version of the [Biopython Tutorial and Cookbook at \n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html \n",
    "    (Last Update â 18 December 2018 (Biopython 1.73)\n",
    "    Same as there except altered to sort on the length of the\n",
    "    open reading frame.\n",
    "    '''\n",
    "    answer = []\n",
    "    seq_len = len(seq)\n",
    "    for strand, nuc in [(+1, seq), (-1, seq.reverse_complement())]:\n",
    "        for frame in range(3):\n",
    "            trans = str(nuc[frame:].translate(trans_table))\n",
    "            trans_len = len(trans)\n",
    "            aa_start = 0\n",
    "            aa_end = 0\n",
    "            while aa_start < trans_len:\n",
    "                aa_end = trans.find(\"*\", aa_start)\n",
    "                if aa_end == -1:\n",
    "                    aa_end = trans_len\n",
    "                if aa_end-aa_start >= min_protein_length:\n",
    "                    if strand == 1:\n",
    "                        start = frame+aa_start*3\n",
    "                        end = min(seq_len,frame+aa_end*3+3)\n",
    "                    else:\n",
    "                        start = seq_len-frame-aa_end*3-3\n",
    "                        end = seq_len-frame-aa_start*3\n",
    "                    answer.append((start, end, strand,\n",
    "                                   trans[aa_start:aa_end]))\n",
    "                aa_start = aa_end+1\n",
    "    answer.sort(key=len_ORF, reverse = True)\n",
    "    return answer\n",
    "\n",
    "def generate_rcoutput_file_name(file_name,suffix_for_saving = \"_rc\"):\n",
    "    '''\n",
    "    from https://github.com/fomightez/sequencework/blob/master/ConvertSeq/convert_fasta_to_reverse_complement.py\n",
    "    Takes a file name as an argument and returns string for the name of the\n",
    "    output file. The generated name is based on the original file\n",
    "    name.\n",
    "    Specific example\n",
    "    =================\n",
    "    Calling function with\n",
    "        (\"sequence.fa\", \"_rc\")\n",
    "    returns\n",
    "        \"sequence_rc.fa\"\n",
    "    '''\n",
    "    main_part_of_name, file_extension = os.path.splitext(\n",
    "        file_name) #from \n",
    "    #http://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python\n",
    "    if '.' in file_name:  #I don't know if this is needed with the os.path.splitext method but I had it before so left it\n",
    "        return main_part_of_name + suffix_for_saving  + file_extension\n",
    "    else:\n",
    "        return file_name + suffix_for_saving + \".fa\"\n",
    "    \n",
    "def add_strand_to_description_line(file,strand=\"-1\"):\n",
    "    '''\n",
    "    Takes a file and edits description line to add \n",
    "    strand info at end.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    new_line = line.strip() + \"; {} strand\\n\".format(strand)\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\nIn {}, strand noted.\".format(file))\n",
    "\n",
    "table = 1 #sets translation table to standard nuclear, see \n",
    "# https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi\n",
    "min_pro_len = 80 #cookbook had the standard `100`. Feel free to adjust.\n",
    "prot_seqs_info = {} #collect as dictionary with strain_id as key. Values to\n",
    "# be list with source id as first item and protein length as second and \n",
    "# strand in source seq as third item, and start and end in source sequence as fourth and fifth,\n",
    "# and file name of protein and gene as sixth and seventh.\n",
    "# Example key and value pair: 'YPS138':['<source id>','<protein length>',-1,52,2626,'<gene file name>','<protein file name>']\n",
    "gene_seqs_fn_list = []\n",
    "prot_seqs_fn_list = []\n",
    "from Bio import SeqIO\n",
    "for raw_seq_filen in collected_seq_files_list:\n",
    "    #strain_id = raw_seq_filen[:-len_genome_fn_end] #if was dealing with source seq\n",
    "    strain_id = raw_seq_filen.split(chromosome_id_prefix)[0].split(\"seq_extracted\")[1]\n",
    "    record = SeqIO.read(\"raw/\"+raw_seq_filen,\"fasta\")\n",
    "    raw_seq_source_fn = strain_id + \".\" + genome_fn_end\n",
    "    raw_seq_source_id = record.description.split(\":\")[0]\n",
    "    orf_list = find_orfs_with_trans(record.seq, table, min_pro_len)\n",
    "    orf_start, orf_end, strand, prot_seq = orf_list[0] #longest ORF seq for protein coding\n",
    "    \n",
    "    location_raw_seq = record.description.rsplit(\":\",1)[1] #get to use in calculating\n",
    "    # the start and end position in original genome sequence.\n",
    "    raw_loc_parts = location_raw_seq.split(\"-\")\n",
    "    start_from_raw_seq = int(raw_loc_parts[0])\n",
    "    end_from_raw_seq = int(raw_loc_parts[1])\n",
    "    length_extracted = len(record) #also to use in calculating relative original\n",
    "    \n",
    "    #Fix negative value. (Somehow Biopython can report negative value when hitting\n",
    "    # end of sequence without encountering stop codon and negatives messes up \n",
    "    # indexing later it seems.)\n",
    "    if orf_start < 0:\n",
    "        orf_start = 0\n",
    "    \n",
    "    \n",
    "    # Trim back to the first Methionine, assumed to be the initiating MET.\n",
    "    # (THIS MIGHT BE A SOURCE OF EXTRA 'LEADING' RESIDUES IN SOME CASES & ARGUES \n",
    "    # FOR LIMITING THE AMOUNT OF FLANKING SEQUENCE ADDED TO ALLOW FOR FUZINESS.)\n",
    "    try:\n",
    "        amt_resi_to_trim = prot_seq.index(\"M\")\n",
    "    except ValueError:\n",
    "        sys.stderr.write(\"**ERROR**When searching for initiating methionine,\\n\"\n",
    "                         \"no Methionine found in the traslated protein sequence.**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    prot_seq = prot_seq[amt_resi_to_trim:]\n",
    "    len_seq_trimmed = amt_resi_to_trim * 3\n",
    "    \n",
    "    # Calculate the adjusted start and end values for the untrimmed ORF\n",
    "    adj_start = start_from_raw_seq + orf_start\n",
    "    adj_end = end_from_raw_seq - (length_extracted - orf_end)\n",
    "    \n",
    "    # Adjust for trimming for appropriate strand.\n",
    "    if strand == 1:\n",
    "        adj_start += len_seq_trimmed\n",
    "        #adj_end += 3 # turns out stop codon is part of numbering biopython returns\n",
    "    elif strand == -1:\n",
    "        adj_end -= len_seq_trimmed\n",
    "        #adj_start -= 3 # turns out stop codon is part of numbering biopython returns\n",
    "    else:\n",
    "        sys.stderr.write(\"**ERROR**No strand match option detected!**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Collect the sequence for the actual gene encoding region from\n",
    "    # the original sequence. This way the original numbers will\n",
    "    # be put in the file.\n",
    "    start_n_end_str = \"{}-{}\".format(adj_start,adj_end)\n",
    "    %run extract_subsequence_from_FASTA.py {raw_seq_source_fn} {raw_seq_source_id} {start_n_end_str}\n",
    "    \n",
    "    # rename the extracted subsequence a more distinguishing name and notify\n",
    "    g_output_file_name = strain_id +\"_\" + gene_name + \"_ortholog_gene.fa\"\n",
    "    !mv {raw_seq_filen} {g_output_file_name} # because the sequence saved happens to \n",
    "    # be same as raw sequence file saved previously, that name can be used to\n",
    "    # rename new file.\n",
    "    gene_seqs_fn_list.append(g_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nRenamed gene file to \"\n",
    "                     \"`{}`.\".format(g_output_file_name))\n",
    "    \n",
    "    # Convert extracted sequence to reverse complement if translation was on negative strand.\n",
    "    if strand == -1:\n",
    "        %run convert_fasta_to_reverse_complement.py {g_output_file_name}\n",
    "        # replace original sequence file with the produced file\n",
    "        produced_fn = generate_rcoutput_file_name(g_output_file_name)\n",
    "        !mv {produced_fn} {g_output_file_name}\n",
    "        # add (after saved) onto the end of the description line for that `-1 strand` \n",
    "        # No way to do this in my current version of convert sequence. So editing descr line.\n",
    "        add_strand_to_description_line(g_output_file_name)\n",
    "\n",
    "    \n",
    "    #When settled on actual protein encoding sequence, fill out\n",
    "    # description to use for saving the protein sequence.\n",
    "    prot_descr =  (record.description.rsplit(\":\",1)[0]+ \" \"+ gene_name \n",
    "                   + \"_ortholog\"+ \"| \" +str(len(prot_seq)) + \" aas | from \" \n",
    "                   + raw_seq_source_id + \" \"\n",
    "                   + str(adj_start) + \"-\"+str(adj_end))\n",
    "    if strand == -1:\n",
    "        prot_descr += \"; {} strand\".format(strand)\n",
    "    \n",
    "    # save the protein sequence as FASTA\n",
    "    chunk_size = 70 #<---amino acids per line to have in FASTA\n",
    "    prot_seq_chunks = [prot_seq[i:i+chunk_size] for i in range(\n",
    "        0, len(prot_seq),chunk_size)]\n",
    "    prot_seq_fa = \">\" + prot_descr + \"\\n\"+ \"\\n\".join(prot_seq_chunks)\n",
    "    p_output_file_name = strain_id +\"_\" + gene_name + \"_protein_ortholog.fa\"\n",
    "    with open(p_output_file_name, 'w') as output:\n",
    "        output.write(prot_seq_fa)\n",
    "    prot_seqs_fn_list.append(p_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nProtein sequence saved as \"\n",
    "                     \"`{}`.\".format(p_output_file_name))\n",
    "    \n",
    "    \n",
    "    # at end store information in `prot_seqs_info` for later making a dataframe \n",
    "    # and then text table for saving summary\n",
    "    #'YPS138':['<source id>',<protein length>,-1,52,2626,'<gene file name>','<protein file name>']\n",
    "    prot_seqs_info[strain_id] = [raw_seq_source_id,len(prot_seq),strand,adj_start,adj_end,\n",
    "                                 g_output_file_name,p_output_file_name]\n",
    "    \n",
    "    sys.stderr.write(\"\\n******END OF A SET OF PROTEIN ORTHOLOG \"\n",
    "                     \"AND ENCODING GENE********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text file of associated details saved as 'VPH1_orthologs_table.tsv'."
     ]
    }
   ],
   "source": [
    "# use `prot_seqs_info` for saving a summary text table (first convert to dataframe?)\n",
    "table_fn_prefix = gene_name + \"_orthologs_table\"\n",
    "table_fn = table_fn_prefix + \".tsv\"\n",
    "pkl_table_fn = table_fn_prefix + \".pkl\"\n",
    "import pandas as pd\n",
    "info_df = pd.DataFrame.from_dict(prot_seqs_info, orient='index',\n",
    "    columns=['descr_id', 'length', 'strand', 'start','end','gene_file','prot_file']) # based on\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html and\n",
    "# note from Python 3.6 that `pd.DataFrame.from_items` is deprecated; \n",
    "#\"Please use DataFrame.from_dict\"\n",
    "info_df.to_pickle(pkl_table_fn)\n",
    "info_df.to_csv(table_fn, sep='\\t') # keep index is default\n",
    "sys.stderr.write(\"Text file of associated details saved as '{}'.\".format(table_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected gene and protein sequences (plus table of details) gathered and saved as `VPH1_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "# pack up archive of gene and protein sequences plus the table\n",
    "seqs_list = gene_seqs_fn_list + prot_seqs_fn_list + [table_fn,pkl_table_fn]\n",
    "archive_file_name = gene_name+\"_ortholog_seqs.tar.gz\"\n",
    "!tar czf {archive_file_name} {\" \".join(seqs_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\nCollected gene and protein sequences\"\n",
    "                 \" (plus table of details) gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tarballed archive to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
